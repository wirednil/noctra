# Milestone 6 ‚Äî "FABRIC" Implementation Plan

> ‚ö†Ô∏è **DEPRECATION NOTICE**
>
> This document (v1) has been superseded by **[M6_IMPLEMENTATION_PLAN_v2.md](M6_IMPLEMENTATION_PLAN_v2.md)** which incorporates critical DuckDB research findings.
>
> **Key Changes in v2:**
> - Arrow integration moved from optional (Phase 5) to **MANDATORY** (Phase 1)
> - New Phase 1.5: Performance Configuration Layer (2 days)
> - Timeline extended from 6 to 7 weeks
> - Dynamic thread configuration (Local vs Remote I/O)
> - AttachmentRegistry for non-persistent ATTACH statements
> - Updated performance targets (CSV 10MB: 500ms‚Üí200ms)
> - Mandatory `PER_THREAD_OUTPUT` for Parquet exports
>
> **Please refer to [M6_IMPLEMENTATION_PLAN_v2.md](M6_IMPLEMENTATION_PLAN_v2.md) for the current implementation plan.**
>
> ---

**Noctra(ü¶Ü DuckDB): Data Fabric Engine**
**Fecha de Inicio:** 11 de noviembre de 2025
**Duraci√≥n:** 6 semanas (11 nov ‚Äî 23 dic 2025) ~~OBSOLETO: Ver v2 para 7 semanas~~
**Versi√≥n Target:** v0.6.0
**Branch:** `claude/duckdb-integration-*`

---

## üéØ OBJETIVO ESTRAT√âGICO

> **Transformar Noctra de "entorno SQL interactivo" a "entorno 4GL de an√°lisis de datos sobre DuckDB"**
> **Los archivos son tablas, el staging desaparece, y el an√°lisis es instant√°neo**

---

## üìã PANORAMA GENERAL DEL MILESTONE

| Antes (Pre-M6) | Despu√©s (M6 - FABRIC) |
|----------------|------------------------|
| `IMPORT` ‚Üí staging ‚Üí query | `USE 'file.csv'` ‚Üí query directo |
| CSV backend manual (900+ l√≠neas) | **Eliminado** ‚Äî DuckDB lo reemplaza |
| JOIN entre CSV imposible | JOIN nativo entre CSV, Parquet, SQLite |
| M√°ximo 100MB por archivo | Streaming ilimitado (zero-copy) |
| SQLite como motor √∫nico | **DuckDB como motor por defecto** |
| `MAP`, `FILTER` redundantes | **Deprecados** ‚Äî SQL est√°ndar |

---

## üóìÔ∏è TIMELINE ‚Äî 6 Semanas ‚Üí 6 Fases

```
Noviembre 2025           Diciembre 2025
11  12  13  14  15  16   17  18  19  20  21  22  23
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ    ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚î§
‚îÇ F1: FUNDACI√ìN         ‚îÇ F2: H√çBRIDO          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                       ‚îÇ F3: RQL 4GL          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                       ‚îÇ F4: EXPORT           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                       ‚îÇ F5: TUI              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                       ‚îÇ F6: RELEASE          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì¶ FASE 1: FUNDACI√ìN ‚Äî Integraci√≥n DuckDB (Semana 1)

**Fecha:** 11-15 nov 2025
**Objetivo:** Reemplazar el backend CSV manual con DuckDB como motor universal.

### Tareas T√©cnicas

#### 1.1 Crear Crate `noctra-duckdb`

**Estructura:**
```
crates/noctra-duckdb/
  ‚îú‚îÄ‚îÄ Cargo.toml
  ‚îú‚îÄ‚îÄ build.rs (si necesario)
  ‚îî‚îÄ‚îÄ src/
      ‚îú‚îÄ‚îÄ lib.rs          # Public API, re-exports
      ‚îú‚îÄ‚îÄ source.rs       # DuckDBSource impl DataSource
      ‚îú‚îÄ‚îÄ engine.rs       # Query execution, parameter binding
      ‚îú‚îÄ‚îÄ extensions.rs   # Parquet, JSON support
      ‚îî‚îÄ‚îÄ error.rs        # Error types
```

**Cargo.toml:**
```toml
[package]
name = "noctra-duckdb"
version = "0.6.0"
edition = "2021"

[dependencies]
duckdb = { version = "1.1", features = ["bundled", "parquet", "json"] }
noctra-core = { path = "../noctra-core" }
anyhow = "1.0"
thiserror = "1.0"
log = "0.4"

[dev-dependencies]
tempfile = "3.0"
env_logger = "0.10"
```

#### 1.2 Implementar `DuckDBSource`

**Archivo:** `crates/noctra-duckdb/src/source.rs`

```rust
use duckdb::{Connection, params};
use noctra_core::{DataSource, ResultSet, Parameters, Value, SourceType, TableInfo, ColumnInfo};
use anyhow::Result;

pub struct DuckDBSource {
    conn: Connection,
    name: String,
}

impl DuckDBSource {
    /// Create in-memory DuckDB connection
    pub fn new_in_memory() -> Result<Self> {
        Ok(Self {
            conn: Connection::open_in_memory()?,
            name: "duckdb".to_string(),
        })
    }

    /// Create file-based DuckDB connection
    pub fn new_with_path(path: &str) -> Result<Self> {
        Ok(Self {
            conn: Connection::open(path)?,
            name: path.to_string(),
        })
    }

    /// Register file as virtual table
    pub fn register_file(&mut self, path: &str, alias: &str) -> Result<()> {
        let ext = std::path::Path::new(path)
            .extension()
            .and_then(|e| e.to_str())
            .unwrap_or("");

        let sql = match ext {
            "csv" | "tsv" => {
                // Auto-detect delimiters, headers, types
                format!("CREATE VIEW {} AS SELECT * FROM read_csv_auto('{}')", alias, path)
            },
            "json" => {
                format!("CREATE VIEW {} AS SELECT * FROM read_json_auto('{}')", alias, path)
            },
            "parquet" => {
                format!("CREATE VIEW {} AS SELECT * FROM read_parquet('{}')", alias, path)
            },
            _ => anyhow::bail!("Unsupported file type: {}", ext),
        };

        self.conn.execute(&sql, [])?;
        log::info!("Registered {} as virtual table '{}'", path, alias);
        Ok(())
    }
}

impl DataSource for DuckDBSource {
    fn query(&self, sql: &str, params: &Parameters) -> Result<ResultSet> {
        let mut stmt = self.conn.prepare(sql)?;

        // Convert Parameters to DuckDB format
        let duckdb_params = params_to_duckdb(params);

        // Execute and convert rows
        let rows = stmt.query_map(&duckdb_params[..], |row| {
            convert_duckdb_row(row)
        })?;

        Ok(ResultSet::from_rows(rows.collect()?))
    }

    fn schema(&self) -> Result<Vec<TableInfo>> {
        let sql = "SELECT table_name FROM information_schema.tables WHERE table_schema = 'main'";
        let mut stmt = self.conn.prepare(sql)?;

        let tables: Vec<String> = stmt
            .query_map([], |row| row.get(0))?
            .collect::<Result<_, _>>()?;

        tables.into_iter()
            .map(|table| {
                let columns = self.get_table_columns(&table)?;
                Ok(TableInfo {
                    name: table,
                    columns,
                })
            })
            .collect()
    }

    fn name(&self) -> &str {
        &self.name
    }

    fn source_type(&self) -> SourceType {
        SourceType::DuckDB
    }
}
```

#### 1.3 Tests B√°sicos

**Archivo:** `crates/noctra-duckdb/src/lib.rs` (integration tests)

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::NamedTempFile;
    use std::io::Write;

    #[test]
    fn test_register_csv() {
        let mut csv = NamedTempFile::new().unwrap();
        writeln!(csv, "id,name,age").unwrap();
        writeln!(csv, "1,Alice,30").unwrap();
        writeln!(csv, "2,Bob,25").unwrap();
        csv.flush().unwrap();

        let mut source = DuckDBSource::new_in_memory().unwrap();
        source.register_file(csv.path().to_str().unwrap(), "users").unwrap();

        let result = source.query("SELECT * FROM users", &Parameters::default()).unwrap();
        assert_eq!(result.rows.len(), 2);
    }

    #[test]
    fn test_schema_introspection() {
        let mut source = DuckDBSource::new_in_memory().unwrap();
        source.conn.execute("CREATE TABLE test (id INTEGER, name TEXT)", []).unwrap();

        let schema = source.schema().unwrap();
        assert_eq!(schema.len(), 1);
        assert_eq!(schema[0].name, "test");
    }
}
```

#### 1.4 Eliminar `csv_backend.rs`

**Acci√≥n:**
```bash
git rm crates/core/src/csv_backend.rs
git rm -r crates/core/tests/csv_backend_tests.rs
```

**Deprecation Notice:**
```rust
// crates/core/src/lib.rs
#[deprecated(since = "0.6.0", note = "Use noctra-duckdb instead")]
pub mod csv_backend;
```

#### 1.5 Feature Flag

**Archivo:** `Cargo.toml` (workspace root)

```toml
[workspace.dependencies]
noctra-duckdb = { path = "crates/noctra-duckdb", optional = true }

[features]
default = ["duckdb-engine"]
duckdb-engine = ["noctra-duckdb"]
sqlite-fallback = []
```

### Entregables Fase 1

- [ ] Crate `noctra-duckdb` funcional
- [ ] `USE 'file.csv' AS alias` funciona con DuckDB
- [ ] Soporte CSV, JSON, Parquet
- [ ] `csv_backend.rs` eliminado
- [ ] Feature flag `duckdb-engine`
- [ ] Tests pasando (>5 tests b√°sicos)

**Criterio de √âxito:**
```bash
cargo test --package noctra-duckdb
# 5+ tests passing
```

---

## üîó FASE 2: MOTOR H√çBRIDO ‚Äî DuckDB + SQLite (Semana 2)

**Fecha:** 16-22 nov 2025
**Objetivo:** Modo h√≠brido por defecto: DuckDB para archivos, SQLite para persistencia.

### Tareas T√©cnicas

#### 2.1 Implementar `QueryEngine::Hybrid`

**Archivo:** `crates/core/src/engine.rs` (NUEVO)

```rust
use noctra_duckdb::DuckDBSource;
use crate::backend::SqliteBackend;

pub enum QueryEngine {
    Sqlite(Box<dyn DatabaseBackend>),
    DuckDB(DuckDBSource),
    Hybrid {
        duckdb: DuckDBSource,
        sqlite: SqliteBackend,
    },
}

impl QueryEngine {
    pub fn new_hybrid() -> Result<Self> {
        Ok(Self::Hybrid {
            duckdb: DuckDBSource::new_in_memory()?,
            sqlite: SqliteBackend::new_in_memory()?,
        })
    }

    pub fn execute(&mut self, nql: &NqlStatement) -> Result<ResultSet> {
        match self {
            Self::DuckDB(conn) => conn.execute_nql(nql),
            Self::Sqlite(backend) => backend.execute(nql),
            Self::Hybrid { duckdb, sqlite } => {
                // Routing logic
                match nql.source_type()? {
                    SourceType::Csv | SourceType::Json | SourceType::Parquet
                        => duckdb.execute_nql(nql),
                    SourceType::Sqlite
                        => sqlite.execute(nql),
                }
            },
        }
    }
}
```

#### 2.2 Routing Inteligente

**L√≥gica:**
```rust
impl QueryEngine {
    fn route_query(&self, source_path: &str) -> EngineType {
        let ext = Path::new(source_path)
            .extension()
            .and_then(|e| e.to_str())
            .unwrap_or("");

        match ext {
            "csv" | "tsv" | "json" | "parquet" => EngineType::DuckDB,
            "db" | "sqlite" | "sqlite3" => EngineType::SQLite,
            _ => EngineType::DuckDB, // Default to DuckDB
        }
    }
}
```

#### 2.3 ATTACH Autom√°tico (SQLite en DuckDB)

**Archivo:** `crates/noctra-duckdb/src/attach.rs`

```rust
impl DuckDBSource {
    pub fn attach_sqlite(&mut self, db_path: &str, alias: &str) -> Result<()> {
        self.conn.execute(
            &format!("ATTACH '{}' AS {} (TYPE SQLITE)", db_path, alias),
            [],
        )?;
        log::info!("Attached SQLite database {} as '{}'", db_path, alias);
        Ok(())
    }
}
```

#### 2.4 Configuraci√≥n TOML

**Archivo:** `~/.config/noctra/config.toml` (ejemplo)

```toml
[engine]
default = "hybrid"  # duckdb, sqlite, hybrid

[duckdb]
temp_dir = "/tmp/noctra-duckdb"
memory_limit = "2GB"
threads = 4
enable_profiling = false

[duckdb.extensions]
auto_install = true
enabled = ["parquet", "json"]

[sqlite]
wal_mode = true
```

**Loader:** `crates/core/src/config.rs`

```rust
use serde::Deserialize;

#[derive(Deserialize)]
pub struct NoctraConfig {
    pub engine: EngineConfig,
    pub duckdb: DuckDBConfig,
    pub sqlite: SqliteConfig,
}

impl NoctraConfig {
    pub fn load() -> Result<Self> {
        let config_path = dirs::config_dir()
            .ok_or_else(|| anyhow!("Config directory not found"))?
            .join("noctra/config.toml");

        if !config_path.exists() {
            return Ok(Self::default());
        }

        let content = std::fs::read_to_string(&config_path)?;
        toml::from_str(&content).map_err(Into::into)
    }
}
```

### Entregables Fase 2

- [ ] `QueryEngine::Hybrid` funcional
- [ ] Routing autom√°tico (CSV ‚Üí DuckDB, SQLite ‚Üí SQLite)
- [ ] ATTACH de SQLite en DuckDB
- [ ] JOIN cross-source funciona
- [ ] Configuraci√≥n TOML cargable
- [ ] Tests: routing, ATTACH, cross-source JOIN

**Criterio de √âxito:**
```sql
USE 'ventas.csv' AS v;
USE 'clientes.db' AS c;

SELECT c.nombre, v.total
FROM v JOIN c.clientes ON v.id = c.id;
-- Resultado: 10 filas
```

---

## üõ†Ô∏è FASE 3: RQL 4GL ‚Äî Extensionalidad Nativa (Semana 3)

**Fecha:** 23-29 nov 2025
**Objetivo:** Consolidar las extensiones √∫nicas de Noctra sobre DuckDB.

### Extensiones a Mantener

#### 3.1 `LET var = valor` ‚Äî Variables de Sesi√≥n

**Estado:** ‚úÖ Ya implementado
**Acci√≥n:** Validar compatibilidad con DuckDB

**Test:**
```sql
LET pais = 'AR';
SELECT * FROM 'ventas.csv' WHERE pais = #pais;
```

#### 3.2 `#var` en SQL ‚Äî Interpolaci√≥n

**Estado:** ‚úÖ Ya implementado
**Acci√≥n:** Validar que funciona con DuckDB queries

#### 3.3 `SHOW VARS` ‚Äî Tabla de Variables

**Estado:** ‚úÖ Ya implementado
**Output:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Variable ‚îÇ Valor  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ pais     ‚îÇ AR     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 3.4 `SHOW SOURCES` ‚Äî Cat√°logo Unificado

**Estado:** ‚úÖ Ya implementado
**Acci√≥n:** Agregar columna `Engine` (DuckDB, SQLite)

**Output:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Alias    ‚îÇ Engine  ‚îÇ Path           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ventas   ‚îÇ DuckDB  ‚îÇ ./ventas.csv   ‚îÇ
‚îÇ clientes ‚îÇ SQLite  ‚îÇ ./clientes.db  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Extensiones a Deprecar

#### 3.5 Deprecar `MAP`, `FILTER`

**Archivo:** `crates/parser/src/parser.rs`

```rust
#[deprecated(since = "0.6.0", note = "Use SQL SELECT with expressions instead")]
pub fn parse_map(&mut self) -> Result<RqlStatement> {
    eprintln!("WARNING: MAP is deprecated. Use SELECT with expressions instead.");
    // ... parsing l√≥gica
}

#[deprecated(since = "0.6.0", note = "Use SQL WHERE clause instead")]
pub fn parse_filter(&mut self) -> Result<RqlStatement> {
    eprintln!("WARNING: FILTER is deprecated. Use WHERE clause instead.");
    // ... parsing l√≥gica
}
```

**Documentaci√≥n:** `docs/MIGRATION.md`

```markdown
## Migrating from MAP/FILTER to SQL Standard

### Before (Pre-M6):
```sql
USE 'datos.csv';
MAP nombre = UPPER(nombre);
FILTER edad > 25;
SELECT * FROM datos;
```

### After (M6+):
```sql
SELECT
    UPPER(nombre) AS nombre,
    *
FROM 'datos.csv'
WHERE edad > 25;
```
```

#### 3.6 Deprecar `OUTPUT TO`

**Reemplazo:** `EXPORT TO ... FORMAT ...`

**Parser:**
```rust
#[deprecated(since = "0.6.0", note = "Use EXPORT TO 'file' FORMAT format")]
pub fn parse_output_to(&mut self) -> Result<RqlStatement> {
    eprintln!("WARNING: OUTPUT TO is deprecated. Use EXPORT TO 'file' FORMAT format");
    // ...
}
```

### Entregables Fase 3

- [ ] `LET`, `#var`, `SHOW VARS` validados con DuckDB
- [ ] `SHOW SOURCES` con columna `Engine`
- [ ] `MAP`, `FILTER`, `OUTPUT TO` marcados como deprecated
- [ ] Warnings en consola al usar comandos deprecados
- [ ] `MIGRATION.md` documentado
- [ ] Tests actualizados

---

## üì§ FASE 4: EXPORT & OUTPUT ‚Äî Unified Output Layer (Semana 4)

**Fecha:** 30 nov - 6 dic 2025
**Objetivo:** `EXPORT` como comando maestro, `OUTPUT TO` eliminado.

### Tareas T√©cnicas

#### 4.1 Implementar `EXPORT` Unificado

**Sintaxis:**
```sql
EXPORT (query) TO 'file.ext' FORMAT format [OPTIONS (...)];
EXPORT table TO 'file.ext' FORMAT format;
```

**Parser:** `crates/parser/src/parser.rs`

```rust
pub enum RqlStatement {
    // ...
    Export {
        source: ExportSource,      // Query or Table
        path: String,
        format: ExportFormat,
        options: HashMap<String, String>,
    },
}

pub enum ExportSource {
    Query(Box<RqlStatement>),
    Table(String),
}

pub enum ExportFormat {
    Csv,
    Json,
    Parquet,
}
```

**Traductor a DuckDB:**

```rust
impl DuckDBSource {
    pub fn export(&self, stmt: &ExportStatement) -> Result<()> {
        let format_str = match stmt.format {
            ExportFormat::Csv => "CSV",
            ExportFormat::Json => "JSON",
            ExportFormat::Parquet => "PARQUET",
        };

        let sql = match &stmt.source {
            ExportSource::Query(query) => {
                format!("COPY ({}) TO '{}' (FORMAT {})", query, stmt.path, format_str)
            },
            ExportSource::Table(table) => {
                format!("COPY {} TO '{}' (FORMAT {})", table, stmt.path, format_str)
            },
        };

        // Apply options
        let sql_with_options = self.apply_export_options(sql, &stmt.options);

        self.conn.execute(&sql_with_options, [])?;
        Ok(())
    }
}
```

#### 4.2 Soporte Multi-Formato

**CSV:**
```sql
EXPORT ventas TO 'out.csv' FORMAT CSV OPTIONS (delimiter=';', header=true);
```

**JSON:**
```sql
EXPORT (SELECT * FROM clientes WHERE activo = 1) TO 'activos.json' FORMAT JSON;
```

**Parquet:**
```sql
EXPORT datos TO 'backup.parquet' FORMAT PARQUET OPTIONS (compression='snappy');
```

### Entregables Fase 4

- [ ] `EXPORT` comando funcional
- [ ] Soporte CSV, JSON, Parquet
- [ ] OPTIONS configurables
- [ ] `OUTPUT TO` completamente deprecado
- [ ] Tests para cada formato
- [ ] Validaci√≥n de paths (security)

**Criterio de √âxito:**
```bash
cargo test --package noctra-core -- export
# 10+ tests passing
```

---

## üé® FASE 5: TUI & UX ‚Äî Data Fabric Experience (Semana 5)

**Fecha:** 7-13 dic 2025
**Objetivo:** Interfaz que refleje el nuevo poder de DuckDB.

### Tareas T√©cnicas

#### 5.1 Status Bar Din√°mico

**Archivo:** `crates/tui/src/noctra_tui.rs`

```rust
fn render_status_bar(&self, area: Rect, buf: &mut Buffer) {
    let engine_icon = match &self.query_engine {
        QueryEngine::DuckDB(_) => "ü¶Ü",
        QueryEngine::Sqlite(_) => "üì¶",
        QueryEngine::Hybrid { .. } => "üîÄ",
    };

    let engine_name = match &self.query_engine {
        QueryEngine::DuckDB(_) => "DuckDB",
        QueryEngine::Sqlite(_) => "SQLite",
        QueryEngine::Hybrid { .. } => "Hybrid",
    };

    let source_info = self.active_source()
        .map(|s| format!("{} ({}, {}, {} rows)",
            s.name(),
            s.source_type(),
            format_size(s.size()?),
            format_rows(s.row_count()?)
        ))
        .unwrap_or_else(|| "No source".to_string());

    let memory_info = format!("{}MB", self.get_memory_usage_mb());
    let time_info = format!("{}ms", self.last_query_time.as_millis());

    let status = format!(
        " {} {} ‚îÇ Source: {} ‚îÇ Memory: {} ‚îÇ {} ",
        engine_icon, engine_name, source_info, memory_info, time_info
    );

    // Render to status bar
    let status_widget = Paragraph::new(status)
        .style(Style::default().bg(Color::Blue).fg(Color::White));
    status_widget.render(area, buf);
}
```

**Output:**
```
Engine: ü¶Ü DuckDB ‚îÇ Source: ventas.csv (CSV, 1.2GB, 1.2M rows) ‚îÇ Memory: 45MB ‚îÇ 8ms
```

#### 5.2 Panel `SOURCES`

**Nuevo Widget:** `crates/tui/src/widgets/sources_panel.rs`

```rust
pub struct SourcesPanel {
    sources: Vec<SourceInfo>,
}

impl Widget for SourcesPanel {
    fn render(self, area: Rect, buf: &mut Buffer) {
        let rows: Vec<Row> = self.sources.iter()
            .map(|s| Row::new(vec![
                s.alias.clone(),
                get_source_icon(&s.source_type),
                format_size(s.size),
                format_rows(s.rows),
            ]))
            .collect();

        let table = Table::new(rows)
            .header(Row::new(vec!["Alias", "Type", "Size", "Rows"]))
            .widths(&[
                Constraint::Length(15),
                Constraint::Length(10),
                Constraint::Length(10),
                Constraint::Length(10),
            ]);

        table.render(area, buf);
    }
}
```

#### 5.3 CLI: `noctra 'file.csv'`

**Archivo:** `crates/cli/src/main.rs`

```rust
#[derive(Parser)]
struct Cli {
    /// File to open directly
    file: Option<String>,

    #[arg(long)]
    engine: Option<EngineType>,

    // ... otros args
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    if let Some(file) = cli.file {
        // Open with automatic USE
        let engine = QueryEngine::new_hybrid()?;
        engine.execute(&format!("USE '{}' AS data", file))?;

        // Launch TUI
        run_tui_with_engine(engine)?;
    } else {
        // Normal mode
        run_tui()?;
    }

    Ok(())
}
```

**Usage:**
```bash
noctra 'ventas.parquet'
# Equivalente a:
# noctra
# > USE 'ventas.parquet' AS v
```

### Entregables Fase 5

- [ ] Status bar din√°mico funcional
- [ ] Panel SOURCES implementado
- [ ] `noctra 'file.csv'` funciona
- [ ] Autocomplete de tablas (b√°sico)
- [ ] Icons por tipo de fuente (ü¶Ü, üì¶)
- [ ] Tests UI (screenshots)

---

## üöÄ FASE 6: RELEASE & DOCUMENTACI√ìN ‚Äî v0.6.0 "FABRIC" (Semana 6)

**Fecha:** 14-23 dic 2025
**Objetivo:** Lanzamiento estable, documentaci√≥n completa, migraci√≥n clara.

### Tareas T√©cnicas

#### 6.1 Tag `v0.6.0`

```bash
git tag -a v0.6.0 -m "Release v0.6.0 - FABRIC (DuckDB Integration)"
git push origin v0.6.0
```

#### 6.2 Documentaci√≥n

**Crear `docs/RQL_EXTENSIONS.md`:**

```markdown
# RQL Extensions Manual

## Variables de Sesi√≥n

### LET
Define una variable de sesi√≥n:
```sql
LET variable = valor;
```

### SHOW VARS
Lista todas las variables:
```sql
SHOW VARS;
```

### #var Interpolation
Usa variables en queries:
```sql
LET pais = 'AR';
SELECT * FROM ventas WHERE pais = #pais;
```

## Multi-Source Management

### USE
Registra una fuente de datos:
```sql
USE 'file.csv' AS alias;
USE 'database.db' AS alias;
```

### SHOW SOURCES
Lista todas las fuentes registradas:
```sql
SHOW SOURCES;
```

### DESCRIBE
Muestra el esquema de una tabla:
```sql
DESCRIBE source.table;
```

## Export

### EXPORT TO
Exporta datos a archivo:
```sql
EXPORT query TO 'file.ext' FORMAT format;
```

Formatos: CSV, JSON, PARQUET

## Deprecated Commands (v0.6.0)

- **MAP** ‚Üí Use SQL SELECT with expressions
- **FILTER** ‚Üí Use SQL WHERE clause
- **OUTPUT TO** ‚Üí Use EXPORT TO
```

**Crear `docs/MIGRATION.md`:**

```markdown
# Migration Guide: v0.5.0 ‚Üí v0.6.0

## Breaking Changes

### csv_backend.rs Removed

**Before:**
```rust
use noctra_core::csv_backend::CsvDataSource;
```

**After:**
```rust
use noctra_duckdb::DuckDBSource;
```

### MAP/FILTER Deprecated

**Before:**
```sql
USE 'datos.csv';
MAP nombre = UPPER(nombre);
FILTER edad > 25;
SELECT * FROM datos;
```

**After:**
```sql
SELECT
    UPPER(nombre) AS nombre,
    *
FROM 'datos.csv'
WHERE edad > 25;
```

### OUTPUT TO Deprecated

**Before:**
```sql
OUTPUT TO 'file.csv' FORMAT CSV;
SELECT * FROM tabla;
```

**After:**
```sql
EXPORT tabla TO 'file.csv' FORMAT CSV;
```

## New Features

### Direct File Queries

```sql
-- No need for USE anymore
SELECT * FROM 'ventas.csv' WHERE region = 'LATAM';
```

### Cross-Source JOINs

```sql
USE 'ventas.csv' AS v;
USE 'clientes.db' AS c;

SELECT c.nombre, v.total
FROM v JOIN c.clientes ON v.id = c.id;
```

### Parquet Support

```sql
SELECT * FROM 'datos.parquet';
EXPORT ventas TO 'backup.parquet' FORMAT PARQUET;
```
```

#### 6.3 Benchmarks

**Archivo:** `benches/duckdb_vs_sqlite.rs`

```rust
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn benchmark_csv_load(c: &mut Criterion) {
    c.bench_function("load_1gb_csv_duckdb", |b| {
        b.iter(|| {
            // Load 1GB CSV with DuckDB
        });
    });

    c.bench_function("load_1gb_csv_sqlite", |b| {
        b.iter(|| {
            // Load 1GB CSV with SQLite (IMPORT)
        });
    });
}

fn benchmark_cross_source_join(c: &mut Criterion) {
    c.bench_function("join_csv_sqlite_duckdb", |b| {
        b.iter(|| {
            // JOIN between CSV and SQLite using DuckDB
        });
    });
}

criterion_group!(benches, benchmark_csv_load, benchmark_cross_source_join);
criterion_main!(benches);
```

**Run:**
```bash
cargo bench --bench duckdb_vs_sqlite
```

**Expected Results:**
- CSV 1GB load: DuckDB <2s vs SQLite ~30s (15x faster)
- JOIN 100K rows: DuckDB <1s vs SQLite ~5s (5x faster)

#### 6.4 CHANGELOG.md

```markdown
# Changelog

## [0.6.0] - 2025-12-23 - "FABRIC"

### Added
- ü¶Ü **DuckDB Integration** as default query engine
- Parquet file support (read/write)
- Cross-source JOINs (CSV + SQLite + Parquet)
- `EXPORT TO 'file' FORMAT format` unified command
- Hybrid mode: DuckDB for files, SQLite for persistence
- Configuration file `~/.config/noctra/config.toml`
- Direct file queries: `SELECT * FROM 'file.csv'`

### Changed
- **BREAKING:** Removed `csv_backend.rs` (replaced by DuckDB)
- **BREAKING:** Default engine is now DuckDB (not SQLite)
- Status bar now shows engine type and source info

### Deprecated
- `MAP expression` ‚Üí Use SQL SELECT with expressions
- `FILTER condition` ‚Üí Use SQL WHERE clause
- `OUTPUT TO 'file'` ‚Üí Use EXPORT TO 'file' FORMAT format

### Fixed
- Performance: 10x faster CSV loading
- Memory: Streaming for large files (no 100MB limit)

### Migration Guide
See `docs/MIGRATION.md` for detailed migration instructions.
```

### Entregables Fase 6

- [ ] Tag `v0.6.0` pushed
- [ ] `RQL_EXTENSIONS.md` completo
- [ ] `MIGRATION.md` completo
- [ ] Benchmarks ejecutados y documentados
- [ ] CHANGELOG.md actualizado
- [ ] Feature flags documentados
- [ ] Tests de regresi√≥n completos (>85% coverage)

---

## ‚úÖ CRITERIOS DE √âXITO GLOBALES

### Funcionales

- ‚úÖ `USE 'file.csv' AS alias` carga archivo sin staging
- ‚úÖ `SELECT * FROM 'file.csv'` funciona directamente
- ‚úÖ JOIN entre CSV y SQLite sin IMPORT
- ‚úÖ EXPORT a CSV, JSON, Parquet
- ‚úÖ Modo h√≠brido por defecto (DuckDB + SQLite)
- ‚úÖ `LET`, `#var`, `SHOW VARS` funcionan con DuckDB
- ‚úÖ `csv_backend.rs` eliminado
- ‚úÖ `MAP`, `FILTER`, `OUTPUT TO` deprecados

### Performance

- ‚úÖ CSV 1GB carga en <2s (vs ~30s con csv_backend)
- ‚úÖ JOIN 100K rows: <1s
- ‚úÖ GROUP BY con agregaciones: <500ms
- ‚úÖ Memoria: <200MB para 1GB CSV (streaming)
- ‚úÖ Parquet 10x m√°s r√°pido que CSV

### Calidad

- ‚úÖ Test coverage: >85%
- ‚úÖ Zero clippy warnings
- ‚úÖ Documentaci√≥n completa (RQL_EXTENSIONS.md, MIGRATION.md)
- ‚úÖ Benchmarks publicados
- ‚úÖ Feature flags documentados

---

## üöß DEPENDENCIAS Y RIESGOS

### Dependencias T√©cnicas

| Dependencia | Versi√≥n | Criticidad | Notas |
|-------------|---------|------------|-------|
| DuckDB | 1.1+ | **CRITICAL** | Motor principal |
| Rust | 1.70+ | High | MSRV |
| Ratatui | 0.29+ | Medium | TUI framework |
| Tokio | 1.48+ | Medium | Async runtime |

### Riesgos Identificados

| Riesgo | Probabilidad | Impacto | Mitigaci√≥n |
|--------|--------------|---------|------------|
| DuckDB API breaking changes | Low | High | Pin version to 1.1.x |
| Performance regression | Medium | High | Benchmarks continuos |
| Migration pain (users) | Medium | Medium | MIGRATION.md detallado |
| Feature flag complexity | Low | Medium | Documentaci√≥n clara |

---

## üìû RECURSOS Y REFERENCIAS

### Documentaci√≥n DuckDB

- [DuckDB SQL Reference](https://duckdb.org/docs/sql/introduction)
- [DuckDB CSV Reader](https://duckdb.org/docs/data/csv/overview)
- [DuckDB Parquet](https://duckdb.org/docs/data/parquet/overview)
- [DuckDB ATTACH DATABASE](https://duckdb.org/docs/sql/statements/attach)

### Noctra Docs

- [PROJECT_STATUS.md](PROJECT_STATUS.md)
- [ROADMAP.md](ROADMAP.md)
- [DESIGN.md](DESIGN.md)
- [RQL-EXTENSIONS.md](RQL-EXTENSIONS.md)

---

## üéØ PR√ìXIMOS PASOS (Post-M6)

Ver **Milestone 7 - "SCRIPT"** para extensiones de scripting:

- `IF/THEN`, `FOR` loops en RQL
- `MACRO`, `CALL` para reutilizaci√≥n de queries
- `RUNSUM()`, `RUNAVG()` funciones de ventana
- `GRAPH BAR`, `GRAPH LINE` visualizaci√≥n ASCII
- `SAVE SESSION`, `LOAD SESSION` persistencia de estado

---

**Noctra(ü¶Ü) ‚Äî Data Fabric Engine**
**"Los archivos son tablas. El staging desaparece. El an√°lisis es instant√°neo."**

---

**√öltima actualizaci√≥n:** 2025-11-11
**Autor:** Claude (Anthropic) + wirednil
**Versi√≥n del Plan:** 1.0
